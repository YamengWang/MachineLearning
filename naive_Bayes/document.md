# 朴素贝叶斯
## 1.模型概述
朴素贝叶斯方法
- 朴素：特征条件独立
- 贝叶斯：基于贝叶斯定理
根据贝叶斯定理，对一个分类问题，给定样本特征x，样本属于类别y的概率是：

```math
p(y|x)=\frac{p(x|y)p(y)}{p(x)}
```
在这里，x是一个特征向量，将设x维度为M。因为朴素的假设，即特征条件独立，根据全概率公式展开，上述公式可以表达为:
```math
p(y=c_k|x)=\frac{\prod_{i=1}^Mp(x_i|y=c_k)p(y=c_k)}{\sum_kp(y=c_k)\prod_{i=1}^Mp(x_i|y=c_k)}
```
这里，只要分别估计出，特征x~i~在每一类的条件概率就可以了。类别y的先验概率可以通过训练集算出，同样通过训练集上的统计，可以得出对应每一类上的，条件独立的特征对应的条件概率向量。
## 2.参数估计
训练集TrainingSet包含N条训练数据

```math
TrainingSet={(x_1,y_1),(x_2,y_2),...,(x_n,y_n)} 
```

其中 

```math
x_i=(x^{(1)}_i,x^{(2)}_i,...,x^{(M)}_i)
```
x~i~是M维向量，y~i~属于K类中的一类。
首先，我们来计算公式中的p(y=c~k~) 

```math
p(y=c_k)=\frac{\sum^N_{i=1}I(y_i=c_k)}{N}
```
其中I(x)为指示函数.

接下来计算分子中的条件概率，设M维特征的第j维有l个取值，则某维特征的某个取值a~jl~，在给定某分类c~k~下的条件概率为： 

```math
p(x^j=a_{jl}|y=c_k)=\frac{\sum^N_{i=1}I(x^j_i=a_{jl},y_i=c_k)}{\sum^N_{i=1}I(y_i=c_k)}
```
## 3.分类

通过学到的概率，给定未分类新实例X，就可以通过上述概率进行计算，得到该实例属于各类的后验概率p(y=c~k~|X)，因为对所有的类来说，贝叶斯公式中的分母的值都相同，所以只计算分子部分即可，具体步骤如下：
- 计算该实例属于y=c~k~类的概率 

```math
p(y=c_k|X)=p(y=c_k)\prod_{j=1}^np(X_i=x_j|y=c_k)
```
- 确定该实例所属的分类y

```math
y=arg~max_{c_k}p(y=c_k|X)
```
于是我们得到了新实例的分类结果
## 4.拉普拉斯平滑

在计算过程中，从样本中算出的概率值可能为0，为解决这个问题，给参数估计步骤中的两个概率计算公式，分子和分母都分别加上一个常数，就可以避免这个问题。更新过后的公式如下：
```math
p(y=c_k)=\frac{\sum^N_{i=1}I(y_i=c_k)+a}{N+Ka}
```
K是类的个数 
```math
p(x^j=a_{jl}|y=c_k)=\frac{\sum^N_{i=1}I(x^j_i=a_{jl},y_i=c_k)+a}{\sum^N_{i=1}I(y_i=c_k)+L_ja}
```
L~j~是第j维特征的最大取值

可以证明，改进以后的公式仍然是概率。平滑因子a=0即为参数估计中实现的最大似然估计，这时会出现在本节开始时提到的0概率问题；而a=1则避免了0概率问题，这种方法被称为拉普拉斯平滑。
## 5.注意
- 编程实现计算先验概率的过程中，由于公式中各因子为相乘的关系，而且大部分因子都非常小，所以程序会下溢或者错误。由于f（x）与ln（f（x）拥有同样的增减的性质，不影响最终结果，故公式可以改为：
```math
p(x^j=a_{jl}|y=c_k)=log(\frac{\sum^N_{i=1}I(x^j_i=a_{jl},y_i=c_k)+a}{\sum^N_{i=1}I(y_i=c_k)+L_ja})
```
-  文本分析的例子中有**词集模型**和**词袋模型**两种
-  在处理垃圾邮件案例中，首先要进行文本解析。